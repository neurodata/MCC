{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying signal components across multiple scales of network topology\n",
    "\n",
    "This demo shows you how to use methods in `graspologic` to analyze patterns\n",
    "in brain connectivity in connectomics datasets. We specifically demonstrate\n",
    "methods for identifying differences in edges and vertices across subjects. \n",
    "\n",
    "This notebook replicates Figure 4 of _Multiscale Comparative Connectomics_.\n",
    "![Fig4](figures/4_signal_tractograms.jpg)\n",
    "\n",
    "Note that tractograms are not produced in this notebook.\n",
    "Tractograms of various signal components were made using DSI Studio.\n",
    "Tracking parameters used in DSI Studio are available in `supplement/tracking_parameters`\n",
    "and the necessary MRI data can be requested from Dr. G. Allan Johnson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from graspologic.datasets import load_mice\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Duke mouse brain dataset\n",
    "\n",
    "Dataset of 32 mouse connectomes derived from whole-brain diffusion\n",
    "magnetic resonance imaging of four distinct mouse genotypes:\n",
    "BTBR T+ Itpr3tf/J (BTBR), C57BL/6J(B6), CAST/EiJ (CAST), and DBA/2J (DBA2).\n",
    "For each strain, connectomes were generated from eight age-matched mice\n",
    "(N = 8 per strain), with a sex distribution of four males and four females.\n",
    "Each connectome was parcellated using asymmetric Waxholm Space, yielding a\n",
    "vertex set with a total of 332 regions of interest (ROIs) symmetrically\n",
    "distributed across the left and right hemispheres. Within a given\n",
    "hemisphere, there are seven superstructures consisting up multiple ROIs,\n",
    "resulting in a total of 14 distinct communities in each connectome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full mouse dataset\n",
    "mice = load_mice()\n",
    "\n",
    "# Stack all adjacency matrices in a 3D numpy array\n",
    "graphs = np.array(mice.graphs)\n",
    "\n",
    "# Sort the connectomes and genotype labels so BTBR is first\n",
    "label_indices = np.argsort(mice.labels).reshape(4, 8)\n",
    "label_indices = label_indices[[1, 0, 2, 3]].reshape(-1)\n",
    "labels = mice.labels[label_indices]\n",
    "graphs = graphs[label_indices]\n",
    "\n",
    "# Get sample parameters\n",
    "n_subjects = mice.meta[\"n_subjects\"]\n",
    "n_vertices = mice.meta[\"n_vertices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Signal Edges\n",
    "\n",
    "The simplest approach for comparing connectomes is to treat them as a _bag of edges_ without considering interactions between the edges.\n",
    "Serially performing univariate statistical analyses at each edge enables the discovery of _signal edges_ whose neurological connectivity differs across categorical or dimensional phenotypes.\n",
    "Here, we demonstrate the possibility of using Distance Correlation (`Dcorr`), a nonparametric universally consistent test, to detect changes in edges.\n",
    "\n",
    "In this model, we assume that each edge in the connectome is independently and\n",
    "identically sampled from some distribution $F_i$, where $i$ represents the group\n",
    "to which the given connectome belongs. In this setting the groups are the mouse\n",
    "genotypes. `Dcorr` allows us to test the following hypothesis:\n",
    "\n",
    "\\begin{align*}\n",
    "H_0:\\ &F_1 = F_2 = \\ldots F_k \\\\\n",
    "H_A:\\ &\\exists \\ j \\neq j' \\text{ s.t. } F_j \\neq F_{j'}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyppo.ksample import KSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the set of graphs by genotype\n",
    "btbr = graphs[labels == \"BTBR\"]\n",
    "b6 = graphs[labels == \"B6\"]\n",
    "cast = graphs[labels == \"CAST\"]\n",
    "dba2 = graphs[labels == \"DBA2\"]\n",
    "\n",
    "connectomes = [btbr, b6, cast, dba2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the connectomes in this dataset are undirected, we only need to do edge\n",
    "comparisons on the upper triangle of the adjacency matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make iterator for traversing the upper triangle of the connectome\n",
    "indices = zip(*np.triu_indices(n_vertices, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_pvals = []\n",
    "\n",
    "for roi_i, roi_j in indices:\n",
    "\n",
    "    # Get the (i,j)-th edge for each connectome\n",
    "    samples = [genotype[:, roi_i, roi_j] for genotype in connectomes]\n",
    "\n",
    "    # Calculate the p-value for the (i,j)-th edge\n",
    "    try:\n",
    "        statistic, pvalue = KSample(\"Dcorr\").test(*samples)\n",
    "    except ValueError:\n",
    "        # A ValueError is thrown when any of the samples have equal edge\n",
    "        # weights (i.e. one of the inputs has 0 variance)\n",
    "        statistic = np.nan\n",
    "        pvalue = 1\n",
    "\n",
    "    edge_pvals.append([roi_i + 1, roi_j + 1, statistic, pvalue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connectomes are a high-dimensional dataype.\n",
    "Thus, statistical tests on components of the connectome (e.g. edge and vertices)\n",
    "results in multiple comparisons.\n",
    "We recommend correcting for multiple comparisons using the Holm-Bonferroni (HB)\n",
    "corection.\n",
    "\n",
    "The algorithm is described below:\n",
    "1. Sort the p-values from lowest-to-highest $P_1, P_2, \\dots, P_n$, where $n$ is the number of tests\n",
    "2. Correct the p-value as $P_1(n), P_2(n-1), \\dots, P_n(1)$\n",
    "3. If any corrected p-value is $>1$, replace with $1$\n",
    "4. If the corrected p-value is less than a significance level $\\alpha$, reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the nested list to a dataframe\n",
    "signal_edges = pd.DataFrame(edge_pvals, columns=[\"ROI_1\", \"ROI_2\", \"stat\", \"pvalue\"])\n",
    "signal_edges.sort_values(by=\"pvalue\", inplace=True, ignore_index=True)\n",
    "\n",
    "# Correct p-values\n",
    "reject, holm_pvalue, _, _ = multipletests(\n",
    "    signal_edges[\"pvalue\"], alpha=0.05, method=\"holm\"\n",
    ")\n",
    "signal_edges[\"holm_pvalue\"] = holm_pvalue\n",
    "signal_edges[\"significant\"] = reject\n",
    "signal_edges.sort_values(by=\"holm_pvalue\", inplace=True, ignore_index=True)\n",
    "signal_edges.to_csv(\"../results/signal_edges.csv\", index=False)\n",
    "signal_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_roi_name(roi):\n",
    "    roi -= 1\n",
    "    hemisphere = \"R\" if roi // 166 else \"L\"\n",
    "    roi = roi % 166\n",
    "    structure = mice.atlas[\"Structure\"].values[roi]\n",
    "    structure = \" \".join(structure.split(\"_\"))\n",
    "    return f\"{structure} ({hemisphere})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 20 strongest signal edges\n",
    "strong_signal_edges = signal_edges.head(20)\n",
    "strong_signal_edges[\"ROI_1\"] = strong_signal_edges[\"ROI_1\"].apply(lookup_roi_name)\n",
    "strong_signal_edges[\"ROI_2\"] = strong_signal_edges[\"ROI_2\"].apply(lookup_roi_name)\n",
    "strong_signal_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that none of the edges achieve significance at $\\alpha=0.05$ following \n",
    "Holm-Bonferroni correction.\n",
    "We might expect this, given that we are correcting for $N=54,946$ tests.\n",
    "Instead of the magnitude, the **ranking of the p-values** can be used to determine signal edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripplot(df, data_column):\n",
    "\n",
    "    kwargs = {\n",
    "        \"alpha\": 0.75,\n",
    "        \"edgecolor\": None,\n",
    "        \"linewidth\": 0,\n",
    "        \"marker\": \"o\",\n",
    "        \"palette\": [\"#e7298a\", \"#1b9e77\", \"#d95f02\", \"#7570b3\"],\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(2.5, 2.5), dpi=150)\n",
    "\n",
    "    g = sns.stripplot(\n",
    "        x=\"Strain\",\n",
    "        y=data_column,\n",
    "        data=df,\n",
    "        jitter=True,\n",
    "        orient=\"v\",\n",
    "        ax=ax,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of edgeweights for the top signal edge across all genotypes.\n",
    "Clearly different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeweight = graphs[:, 121 - 1, 230 - 1]\n",
    "edgeweight = pd.DataFrame({\"Edgeweight\": edgeweight, \"Strain\": labels})\n",
    "g = stripplot(edgeweight, \"Edgeweight\")\n",
    "g.ticklabel_format(style=\"sci\", scilimits=(0, 0), axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Signal Vertices\n",
    "\n",
    "A sample of connectomes can be jointly embedded in a low-dimensional Euclidean space using the omnibus embedding (`omni`).\n",
    "A host of machine learning tasks can be accomplished with this joint embedded representation of the connectome, such as clustering or classification of vertices.\n",
    "Here, we use the embedding to formulate a statistical test that can be used to identify vertices that are strongly associated with given phenotypes.\n",
    "According to a Central Limit Theorem for `omni`, these latent positions are universally consistent and asymptotically normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "from graspologic.embed import OmnibusEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointly embed graphs using OMNI\n",
    "embedder = OmnibusEmbed()\n",
    "omni_embedding = embedder.fit_transform(graphs)\n",
    "omni_embedding = omni_embedding.reshape(-1, omni_embedding.shape[-1])\n",
    "print(f\"Omnibus embedding shape is {omni_embedding.shape}\")\n",
    "\n",
    "# Convert array to a dataframe\n",
    "omni_embedding = pd.DataFrame(\n",
    "    omni_embedding, columns=[f\"omni_{i + 1}\" for i in range(omni_embedding.shape[-1])]\n",
    ").astype(np.float64)\n",
    "omni_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct identifiers for each embedded vertex\n",
    "left = mice.atlas[\"ROI\"].unique()\n",
    "right = left + 166\n",
    "rois = np.append(left, right)\n",
    "\n",
    "participants = mice.participants[\"participant_id\"]\n",
    "participants = participants.apply(lambda x: x.split(\"-\")[1])\n",
    "\n",
    "identifiers = np.array(list(product(participants, rois))).reshape(-1, 2)\n",
    "identifiers = pd.DataFrame(identifiers, columns=[\"participant_id\", \"ROI\"])\n",
    "identifiers[\"ROI\"] = identifiers[\"ROI\"].astype(np.int64)\n",
    "identifiers[\"genotype\"] = np.array([[strain] * 332 for strain in labels]).reshape(-1)\n",
    "\n",
    "omni = pd.concat([omni_embedding, identifiers], axis=1)\n",
    "omni.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 32 mice, `omni` embeds each vertex in the connectome to a\n",
    "latent position vector $x_i \\in \\mathbb{R}^5$.\n",
    "We test for differences in the distribution of vertex latent positions using \n",
    "the `R` implementation of `MANOVA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i omni -i n_vertices -o signal_vertices\n",
    "\n",
    "suppressPackageStartupMessages(require(tidyverse))\n",
    "\n",
    "col1 <- which(grepl(\"omni\", names(omni))) # column indices for the embeddings\n",
    "col2 <- which(grepl(\"genotype\", names(omni))) # column index for the genotype\n",
    "\n",
    "embedding <- colnames(omni)[col1]\n",
    "genotype <- colnames(omni)[col2]\n",
    "form <- paste0(\"cbind(\", paste(embedding, collapse=\", \"), \") ~ \", genotype)\n",
    "\n",
    "pvec <- rep(0, n_vertices)\n",
    "pillai <- rep(0, n_vertices)\n",
    "F <- rep(0, n_vertices)\n",
    "num.df <- rep(0, n_vertices)\n",
    "den.df <- rep(0, n_vertices)\n",
    "\n",
    "for (i in 1 : n_vertices) {\n",
    "    omni.v <- omni[which(omni$ROI == i), ]\n",
    "    ans <- manova(as.formula(form), data=omni.v)\n",
    "    pvec[i] <- summary(ans)$stats[1, \"Pr(>F)\"]\n",
    "    pillai[i] <- summary(ans)$stats[1, \"Pillai\"]\n",
    "    F[i] <- summary(ans)$stats[1, \"approx F\"]\n",
    "    num.df[i] <- summary(ans)$stats[1, \"num Df\"]\n",
    "    den.df[i] <- summary(ans)$stats[1, \"den Df\"]\n",
    "}\n",
    "\n",
    "signal_vertices <- data.frame(ROI=unique(omni$ROI), pillai=pillai, F=F, num.df=num.df, den.df=den.df, pvalue=pvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct p-values\n",
    "signal_vertices.sort_values(by=\"pvalue\", inplace=True, ignore_index=True)\n",
    "reject, holm_pvalue, _, _ = multipletests(\n",
    "    signal_vertices[\"pvalue\"], alpha=0.05, method=\"holm\"\n",
    ")\n",
    "signal_vertices[\"holm_pvalue\"] = holm_pvalue\n",
    "signal_vertices[\"significant\"] = reject\n",
    "signal_vertices.sort_values(by=\"holm_pvalue\", inplace=True, ignore_index=True)\n",
    "signal_vertices.to_csv(\"../results/signal_vertices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 strongest signal edges\n",
    "strong_signal_vertices = signal_vertices.head(10)\n",
    "strong_signal_vertices[\"ROI\"] = strong_signal_vertices[\"ROI\"].apply(lookup_roi_name)\n",
    "strong_signal_vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strongest signal vertex is the left hemisphere corpus callosum.\n",
    "THe corpus callosum is the bridge between the left and right hemispheres of the brain.\n",
    "In BTBR mice, this connection is absent (see the tractograms above).\n",
    "We would expect our methods to recover this vertex as highly heterogeneous\n",
    "across strains. This experiment validates this hypothesis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_cc = omni.query(\"ROI == 121\")[[\"omni_1\", \"genotype\"]]\n",
    "left_cc.columns = [\"Embedding Dim. 1\", \"Strain\"]\n",
    "g = stripplot(left_cc, \"Embedding Dim. 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Signal Communities\n",
    "Communities are the connections between distinct superstructures in the brain (effectively subgraphs of the connectome).\n",
    "To test for differences in these subgraphs, we use `DCorr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "Point = namedtuple(\"Point\", [\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_point(community, hemisphere):\n",
    "    \"\"\"Make points from database queries.\"\"\"\n",
    "    expr = f\"block == '{community}' and hemisphere == '{hemisphere}'\"\n",
    "    point = Point(*mice.blocks.query(expr).values[0][2:])\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_edges(point_1, point_2, sample):\n",
    "    return sample[:, point_1.x : point_1.y, point_2.x : point_2.y].reshape(8, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_community_name(block, hemisphere):\n",
    "    block = \" \".join([struct.capitalize() for struct in block.split(\"_\")])\n",
    "    return f\"{block} ({hemisphere})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_communities = []\n",
    "\n",
    "for (_, community_1), (_, community_2) in combinations_with_replacement(\n",
    "    mice.blocks.iterrows(), r=2\n",
    "):\n",
    "\n",
    "    point_1 = _get_point(community_1.block, community_1.hemisphere)\n",
    "    point_2 = _get_point(community_2.block, community_2.hemisphere)\n",
    "\n",
    "    community_1 = _get_community_name(community_1.block, community_1.hemisphere)\n",
    "    community_2 = _get_community_name(community_2.block, community_2.hemisphere)\n",
    "\n",
    "    edges = [_get_edges(point_1, point_2, sample) for sample in connectomes]\n",
    "\n",
    "    try:\n",
    "        stat, pvalue = KSample(\"Dcorr\").test(*edges)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        stat, pvalue = np.nan, 1\n",
    "\n",
    "    signal_communities.append([community_1, community_2, stat, pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_communities = pd.DataFrame(\n",
    "    signal_communities, columns=[\"Community 1\", \"Community 2\", \"statistic\", \"pvalue\"]\n",
    ")\n",
    "\n",
    "# Correct p-values\n",
    "signal_communities = signal_communities.sort_values([\"pvalue\"])\n",
    "reject, holm_pvalue, _, _ = multipletests(\n",
    "    signal_communities[\"pvalue\"], alpha=0.05, method=\"holm\"\n",
    ")\n",
    "signal_communities[\"holm_pvalue\"] = holm_pvalue\n",
    "signal_communities[\"significant\"] = reject\n",
    "signal_communities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_communities.to_csv(\"../results/signal_communities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_r = _get_point(\"white_matter\", \"R\")\n",
    "wm_r_edgeweight = graphs[:, wm_r.x : wm_r.y, wm_r.x : wm_r.y].reshape(32, -1)\n",
    "wm_r_mean = wm_r_edgeweight.mean(axis=1)\n",
    "\n",
    "avg_connectivity = pd.DataFrame({\"Mean Edgeweight\": wm_r_mean, \"Strain\": labels})\n",
    "g = stripplot(avg_connectivity, \"Mean Edgeweight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mcc]",
   "language": "python",
   "name": "conda-env-mcc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}